# -*- coding: utf-8 -*-
"""Business_Insights_EDA_and_Cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ML7e25_lMIiSEuhEB19KC80BTyykNTSD
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
import re # For Regular expression

# Load datasets
customer_file_path = "/content/drive/MyDrive/PEI DataSets/Customer.xlsx"
order_file_path = "/content/drive/MyDrive/PEI DataSets/Order.csv"
shipping_file_path = "/content/drive/MyDrive/PEI DataSets/Shipping.json"

# customer_df = pd.read_excel(customer_file_path, engine="xlrd")
# Engine= xlrd as the file is in xls format which is old one
# customer_file_path = "/content/drive/MyDrive/PEI DataSets/Customer.xls"
#customer_df = pd.read_excel(customer_file_path, engine="xlrd")

# Load Customer Data
customer_df = pd.read_excel(customer_file_path)

# Load Order Data
order_df = pd.read_csv(order_file_path)

# Load Shipping Data
shipping_df = pd.read_json(shipping_file_path)

# Function to Perform EDA + Data Cleaning
# https://emojidb.org/stats-emojis emojis or icons are taken from this website for better look and feel

def perform_eda_and_clean(df, name):
    print(f"\n📊 EDA + Data Cleaning for {name} Dataset:")

    # 📝 1. Columns and Data Types
    print("\n📝 Columns and Data Types:")
    print(df.info())

    # 🔍 2. Printing First 5 Rows
    print("\n🔍 First 5 Rows:")
    print(df.head())

    # 📌 3. Check for Missing values
    print("\n Missing Values Count:")
    print(df.isnull().sum())

    # 📈 4. Summary Statistics for Numerical Data
    print("\n📈 Summary Statistics (Numerical Data):")
    print(df.describe())

    # ✅ 5. Unique Values Per Column
    print("\n✅ Unique Values Per Column:")
    print(df.nunique())

    # 🔍 6. Check for Special Characters in String Columns
    print("\n🔍 Special Character Check:")

    # Define regex pattern for special characters (excluding space, a-z, A-Z, 0-9, and basic punctuation)
    special_char_pattern = re.compile(r'[^A-Za-z0-9\s.,]')

    for col in df.select_dtypes(include=["object"]).columns:
        # Find all special characters in the column
        special_chars = df[col].astype(str).apply(lambda x: set(re.findall(special_char_pattern, x)))

        # Get unique special characters found in the column
        unique_special_chars = set().union(*special_chars)

        if unique_special_chars:
            print(f"⚠️ Column `{col}` contains {len(unique_special_chars)} unique special characters: {unique_special_chars}")
        else:
            print(f"✅ Column `{col}` has no special characters.")

        # 🔥 7. Data Cleaning - Remove Special Characters
        df[col] = df[col].apply(lambda x: re.sub(special_char_pattern, '', str(x)))

    # 🔥 8. Handle Missing Values
    for col in df.columns:
        if df[col].isnull().sum() > 0:  # If missing values exist
            if df[col].dtype == "object":
                df[col].fillna("Unknown", inplace=True)  # Fill text columns with "Unknown"
            else:
                df[col].fillna(df[col].median(), inplace=True)  # Fill numeric columns with median

    # 🔥 9. Remove Duplicate Rows
    before = len(df)
    df.drop_duplicates(inplace=True)
    after = len(df)
    print(f"\n✅ Removed {before - after} duplicate rows.")

    # 🔥 10. Ensure Correct Data Types
    if "Age" in df.columns:
        df["Age"] = df["Age"].astype(int)  # Convert Age to integer

    if "Amount" in df.columns:
        df["Amount"] = df["Amount"].astype(float)  # Convert Amount to float

    print("\n✅ Data Cleaning Completed! Dataset is Ready for Analysis 🚀")
    return df  # Return cleaned DataFrame

# Perform EDA on each dataset
customer_df = perform_eda_and_clean(customer_df, "Customer")

# Perform EDA on Order dataset
order_df = perform_eda_and_clean(order_df, "Order")

shipping_df = perform_eda_and_clean(shipping_df, "Shipping")

'''
#Check for Duplicates in each dataset
df = order_df
duplicates = df[df.duplicated(keep=False)]  # Get all duplicate rows
total_duplicates = df.duplicated().sum()  # Count duplicate rows
print(f"\n📊 Checking Duplicates in {df} Dataset:")
print(f"🔄 Total Duplicate Rows: {total_duplicates}") 

'''

customer_df.head()

order_df.head()

shipping_df.head()

# Merge Order and Shipping Data
order_shipping_df = order_df.merge(shipping_df, on="Customer_ID", how="left")

# Merge with Customer Data
final_df = order_shipping_df.merge(customer_df, on="Customer_ID", how="left")

final_df.head()

"""
✅ 1. Total amount spent for "Pending" delivery status per country
"""
pending_df = final_df[final_df["Status"] == "Pending"]
total_amount_pending = pending_df.groupby("Country")["Amount"].sum().reset_index()
print("\n🔥 Total Amount Spent for Pending Deliveries by Country:\n", total_amount_pending)

# 🔥 2. Total Transactions, Quantity Sold, and Amount Spent per Customer (with Product Details)
customer_summary = order_df.groupby(["Customer_ID", "Item"]).agg(
    Total_Transactions=("Order_ID", "count"),
    Total_Quantity_Sold=("Item", "count"),
    Total_Amount_Spent=("Amount", "sum")
).reset_index()

print("\n📌 Customer Transactions Summary:")
print(customer_summary.head())

"""
✅ 3. Maximum product purchased per country
"""
max_product_per_country = final_df.groupby(["Country", "Item"]).size().reset_index(name="Total_Purchases")
max_product_per_country = max_product_per_country.loc[max_product_per_country.groupby("Country")["Total_Purchases"].idxmax()]
print("\n🔥 Maximum Product Purchased in Each Country:\n\n", max_product_per_country)

"""
✅ 4. Most purchased product based on age category (<30 and ≥30)
"""
# Categorizing Age Groups
final_df["Age_Category"] = final_df["Age"].apply(lambda x: "Below 30" if x < 30 else "Above 30")

most_purchased_product_age = final_df.groupby(["Age_Category", "Item"]).size().reset_index(name="Total_Purchases")
most_purchased_product_age = most_purchased_product_age.loc[most_purchased_product_age.groupby("Age_Category")["Total_Purchases"].idxmax()]
print("\n🔥 Most Purchased Product by Age Category:\n", most_purchased_product_age)

"""
✅ 5. Country with Minimum Transactions and Sales Amount
"""
country_sales = final_df.groupby("Country").agg(
    Total_Transactions=("Order_ID", "count"),
    Total_Sales_Amount=("Amount", "sum")
).reset_index()
min_transaction_country = country_sales.loc[country_sales["Total_Transactions"].idxmin()]
min_sales_country = country_sales.loc[country_sales["Total_Sales_Amount"].idxmin()]

print("\n🔥 Country with Minimum Transactions:\n", min_transaction_country)
print("\n🔥 Country with Minimum Sales Amount:\n", min_sales_country)